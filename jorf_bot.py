#!/usr/bin/env python3
"""
Bot pour surveiller le Journal Officiel et envoyer un r√©sum√© des articles pertinents
pour la pr√©paration du concours INSP via Alertzy.
"""

import os
import feedparser
import requests
from openai import OpenAI
import logging
from datetime import datetime

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class JORFBot:
    def __init__(self):
        self.rss_url = "https://droit.org/flux/jorf.rss"
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.alertzy_key = os.getenv('ALERTZY_KEY')
        
    def fetch_rss_feed(self):
        """R√©cup√®re le flux RSS du Journal Officiel"""
        try:
            logger.info("R√©cup√©ration du flux RSS du Journal Officiel...")
            feed = feedparser.parse(self.rss_url)
            
            if feed.bozo:
                logger.warning(f"Probl√®me de parsing RSS: {feed.bozo_exception}")
            
            logger.info(f"Flux r√©cup√©r√© avec {len(feed.entries)} articles")
            
            # Log de tous les titres re√ßus du flux RSS
            logger.info("Tous les titres re√ßus du flux RSS:")
            for i, entry in enumerate(feed.entries, 1):
                title = entry.get('title', 'Sans titre')
                logger.info(f"  {i}. {title}")
            
            return feed
        except Exception as e:
            logger.error(f"Erreur lors de la r√©cup√©ration du flux RSS: {e}")
            return None
    
    def filter_relevant_articles(self, feed):
        """Filtre les articles pertinents pour la pr√©paration INSP"""
        if not feed or not feed.entries:
            return []
        
        relevant_keywords = [
            "politique publique", "fonction publique", "administration", "gouvernement",
            "ministre", "secr√©taire d'√©tat", "pr√©fet", "directeur", "nomination",
            "d√©cret", "loi", "ordonnance", "arr√™t√©", "circulaire",
            "concours", "recrutement", "formation", "INSP", "ENA",
            "budget", "finance", "√©conomie", "social", "sant√©", "√©ducation",
            "justice", "int√©rieur", "d√©fense", "affaires √©trang√®res",
            "transition √©cologique", "num√©rique", "innovation"
        ]
        
        relevant_articles = []
        
        for entry in feed.entries:
            title = entry.get('title', '').lower()
            description = entry.get('description', '').lower()
            content = f"{title} {description}"
            
            # V√©rifier si l'article contient des mots-cl√©s pertinents
            if any(keyword in content for keyword in relevant_keywords):
                relevant_articles.append({
                    'title': entry.get('title', ''),
                    'link': entry.get('link', ''),
                    'description': entry.get('description', ''),
                    'published': entry.get('published', '')
                })
        
        logger.info(f"{len(relevant_articles)} articles pertinents trouv√©s sur {len(feed.entries)}")
        return relevant_articles
    
    def generate_summary_with_ai(self, articles):
        """G√©n√®re un r√©sum√© des articles avec OpenAI en divisant en plusieurs appels"""
        if not articles:
            return "Aucun article pertinent trouv√© aujourd'hui."
        
        # Diviser les articles en chunks pour √©viter le d√©passement de contexte
        chunk_size = 20  # Nombre d'articles par chunk (‚âà 6000 tokens)
        chunks = [articles[i:i + chunk_size] for i in range(0, len(articles), chunk_size)]
        
        logger.info(f"Articles divis√©s en {len(chunks)} chunks de {chunk_size} articles maximum")
        
        all_summaries = []
        
        for chunk_idx, chunk in enumerate(chunks, 1):
            logger.info(f"Traitement du chunk {chunk_idx}/{len(chunks)} avec {len(chunk)} articles")
            
            # Pr√©parer le contenu pour ce chunk
            articles_text = ""
            for i, article in enumerate(chunk, 1):
                title = article['title'][:200] + "..." if len(article['title']) > 200 else article['title']
                description = article['description'][:400] + "..." if len(article['description']) > 400 else article['description']
                articles_text += f"\n{i}. {title}\n   Lien: {article['link']}\n   Description: {description}\n"
            
            # Log des titres de ce chunk
            logger.info(f"Titres du chunk {chunk_idx}:")
            for i, article in enumerate(chunk, 1):
                title = article['title'][:100] + "..." if len(article['title']) > 100 else article['title']
                logger.info(f"  {i}. {title}")
            
            prompt = f"""
Tu es un assistant sp√©cialis√© dans l'analyse du Journal Officiel fran√ßais pour des stagiaires pr√©parant le concours de l'INSP (Institut National du Service Public).

Voici une partie des articles du Journal Officiel d'aujourd'hui (chunk {chunk_idx}/{len(chunks)}) :

{articles_text}

Analyse ces articles et cr√©e un r√©sum√© structur√© et informatif pour des stagiaires pr√©parant le concours INSP. 

Concentre-toi sur :
- Les textes importants pour la vie publique, notamment en lien avec l'actualit√©
- Les politiques publiques nouvelles ou modifi√©es
- Les √©volutions institutionnelles
- Tres tres tres peu de nominations sauf si elles sont vraiment hyper importantes (ministres surtout, ou personnages politiques importants), et pas de mobilites
- Si il te reste de la place dans ton contexte tu peux ajouter des choses moins importantes
- Pour des groupes de textes tres similaires tu peux tout r√©sumer en une seule phrase

Format de sortie :
- Utilise des emojis pour rendre le message plus attractif
- Structure avec des titres clairs
- Sois hyper concis mais informatif
- Adapte le ton pour une notification mobile
- Limite √† 1000 caract√®res maximum pour ce chunk, mais si tu n'as rien tu n'es pas oblig√© de remplir l'espace pour rien

Commence par "üì∞ JOURNAL OFFICIEL - Partie {chunk_idx} üì∞"
"""

            try:
                response = self.openai_client.chat.completions.create(
                    model="gpt-4",
                    messages=[
                        {"role": "system", "content": "Tu es un expert en droit administratif et en pr√©paration aux concours de la fonction publique fran√ßaise."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1000,
                    temperature=0.7
                )
                
                chunk_summary = response.choices[0].message.content
                all_summaries.append(chunk_summary)
                logger.info(f"Chunk {chunk_idx} trait√© avec succ√®s")
                
            except Exception as e:
                logger.error(f"Erreur lors du traitement du chunk {chunk_idx}: {e}")
                all_summaries.append(f"Erreur lors du traitement du chunk {chunk_idx}: {str(e)}")
        
        # Concat√©ner tous les r√©sum√©s
        if len(all_summaries) == 1:
            final_summary = all_summaries[0]
        else:
            final_summary = "üì∞ JOURNAL OFFICIEL - R√©sum√© du jour üì∞\n\n"
            for i, summary in enumerate(all_summaries, 1):
                # Nettoyer le r√©sum√© (enlever les en-t√™tes r√©p√©t√©es)
                clean_summary = summary.replace(f"üì∞ JOURNAL OFFICIEL - Partie {i} üì∞", "").strip()
                final_summary += f"{clean_summary}\n\n"
        
        logger.info(f"R√©sum√© final g√©n√©r√© avec {len(all_summaries)} chunks")
        return final_summary
    
    def send_to_alertzy(self, message):
        """Envoie le message via Alertzy"""
        if not self.alertzy_key:
            logger.error("Cl√© Alertzy manquante")
            return False
        
        try:
            url = "https://alertzy.app/send"
            data = {
                "accountKey": self.alertzy_key,
                "title": "üì∞ Journal Officiel - R√©sum√© INSP",
                "message": message,
                "priority": "normal"
            }
            
            response = requests.post(url, data=data)
            
            if response.status_code == 200:
                logger.info("Message envoy√© avec succ√®s via Alertzy")
                return True
            else:
                logger.error(f"Erreur lors de l'envoi Alertzy: {response.status_code} - {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"Erreur lors de l'envoi Alertzy: {e}")
            return False
    
    def run(self):
        """Fonction principale du bot"""
        logger.info("D√©marrage du bot JORF")
        
        # R√©cup√©rer le flux RSS
        feed = self.fetch_rss_feed()
        if not feed:
            logger.error("Impossible de r√©cup√©rer le flux RSS")
            return
        
        # Filtrer les articles pertinents
        relevant_articles = self.filter_relevant_articles(feed)
        
        if not relevant_articles:
            message = "üì∞ JOURNAL OFFICIEL - R√©sum√© du jour üì∞\n\nAucun article particuli√®rement pertinent pour la pr√©paration INSP aujourd'hui."
        else:
            # G√©n√©rer le r√©sum√© avec l'IA
            summary = self.generate_summary_with_ai(relevant_articles)
            message = summary
        
        # Envoyer via Alertzy
        if self.send_to_alertzy(message):
            logger.info("Bot ex√©cut√© avec succ√®s")
        else:
            logger.error("√âchec de l'envoi via Alertzy")

def main():
    """Point d'entr√©e principal"""
    bot = JORFBot()
    bot.run()

if __name__ == "__main__":
    main()
